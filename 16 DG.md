# Discontinuous Galerkin methods

$$
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
\newcommand{\b}{\mathbf b}
\newcommand{\e}{\mathbf e}
\newcommand{\f}{\mathbf f}
\newcommand{\j}{\mathbf j}
\newcommand{\n}{\mathbf n}
\newcommand{\u}{\mathbf u}
\newcommand{\v}{\mathbf v}
\newcommand{\w}{\mathbf w}
\newcommand{\U}{\mathbf U}
\newcommand{\I}{\mathcal I}
\newcommand{\bzero}{\mathbf 0}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\norm}[1]{\big\lVert #1 \big\rVert}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\angles}[1]{\left\langle #1 \right\rangle}
\newcommand{\curlies}[1]{\left\lbrace #1 \right\rbrace}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\d}{\, \text{d}}
\newcommand{\dbyd}[2]{\frac{\d #1}{\d #2}}
\newcommand{\partials}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\BigO}{\mathcal O}
\newcommand{\disclapl}[1][]{\partial_{#1} \overline \partial_{#1}}
\newcommand{\Domain}{\overline \Omega}
\newcommand{\uja}{\hat u_1^j}
\newcommand{\ujb}{\hat u_2^j}
\newcommand{\vja}{\hat v_1^j}
\newcommand{\vjb}{\hat v_2^j}
\DeclareMathOperator{\span}{span}
\DeclareMathOperator{\ess}{ess}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\sign}{sign}
$$

## Discontinuous Galerkin methods

Our set of functions is

$$
V_h^\alpha = \curlies{ v_h \in L^2(\Omega_h) : v_h \bigg\vert_{K_j} \in P^k(K_j) \text{ for each } K_j \subset \Omega }
$$

DG methods are higher order finite volume methods, i.e. with polynomials of degree $k > 0$ (as opposed to FV which uses $k=0$):

$$
\int_{K_j} v_h^j \partial_t u_h^j \d x - \int_{K_j} f(u_h^i) \partial_x v_h \d x + \hat f()
$$

We will work with $k=1$, so we approximate the solution $u(x, t)$ by a linear polynomial in each element.

$$
u(x, t) \bigg\vert_{K_j} \approx u_h(x, t) \bigg\vert_{K_j} = \hat u_1^j (t) \psi_1(x) + \hat u_2^j (t) \psi_2(x)
$$

where $\psi_1, \psi_2$ are linear basis functions (as opposed to constant) and $\hat u_1^j(t), \hat u_2^j(t)$ are the expansion coefficients.

## Reference elements

To simplify integrals in our DG discretization, we use a reference element $\hat K=(-1, 1)$

To map the reference element to a physical element $K_j$:

$$
\begin{align*}
F_{K_j} : (-1, 1) &\to (x_{j-1}, x_j) \\
\xi &\mapsto \frac{1}{2}{(x_{j-1} + x_j)} + \frac{1}{2} h_j \xi
\end{align*}
$$

We will use Legendre basis functions for convenience (results in fewer terms), though Lagrange basis functions (as in FEM) are valid as well. The first two Legendre basis functions on the reference element are:

$$
\hat \psi_1(\xi) = 1 \text{ and } \hat \psi_2(\xi) = \xi
$$

This means our $\uja$ is the mean and $\ujb$ is the slope of our discrete solution.

Then our physical basis functions are

$$
\psi_m(x) = \hat \psi_m(\inv F_{K_j}(x)) \tag{$\xi = \inv F_{K_j}(x)$}
$$

These are orthogonal on the reference element:

$$
\int_{\hat K} \psi_i(\xi) \psi_j(\xi) \d \xi = \frac{2}{2(i - 1) + 1} \delta_{ij} = \begin{cases} 1 & i = j \\ 0 & i \neq j \end{cases}
$$

Substituting our reference elements into our DG formulation,

$$
\int_{K_j} (\hat v_1^j \psi_1(x) + \hat v_2^j \psi_2(x)) \  \partial_t (\hat u_1^j(t) \psi_1(x) + \hat u_2^j(t) \psi_2(x) - \int_{K_j} f(u_m^j(x, t)) \ \partial_x (\hat v_1^j \psi_1(x) + \hat v_2^j \psi_2(x)) \\
+ \hat f_j \parens{ \hat v_1^j \psi_1(x_j) + \hat v_2^j \psi_2(x_j) } - \hat f_{j-1} \parens{ \hat v_1^j \psi_1(x_{j-1}) + \hat v_2^j \psi_2(x_{j-1}) }
$$

lmao

### IC (?)

#### Step 1

$$
\int_{K_j} \parens{ \hat v_1^j \psi_1(x) + \hat v_2^j \psi_2(x) } \parens{ \hat u_1^j(0) \psi_1(x) + \hat u_2^j(0)\psi_2(x) } \d x \\
= \int_{K_j} \parens{ \hat v_1^j \psi_1(x) + \hat v_2^j \psi_2(x) } u_0(x) \d x
$$

Note that the expansion coefficients $\hat v_1^j, \hat v_2^j, \hat u_1^j, \hat u_2^j$ do not depend on $x$, so they can be taken out of the integral:
$$
\begin{align*}
v_1^j \parens{\uja(0) \int_{K_j} \psi_1(x) \psi_1(x) \d x + \ujb(0) \int_{K_j} \psi_1(x) \psi_2(x) \d x} \\
+ v_2^j \parens{\uja(0) \int_{K_j} \psi_2(x) \psi_1(x) \d x + \ujb(0) \int_{K_j} \psi_2(x) \psi_2(x) \d x} \\
= \vja \parens{ \int_{K_j} \psi_1(x) u_0(x) \d x } + \vjb \parens{ \int_{K_j} \psi_2(x) u_0(x) \d x }
\end{align*}
$$

#### Step 2: basis linear independence

Since the basis functions are linearly independent, we can split this into two equations:

For $\vja$

sodgjhosd

For $\vjb$

fsjgsdiogu

#### Step 3: map to $\hat K$



#### Step 4: use orthogonality

$$
\begin{align*}
\int_{-1}^1 \hat \psi_1 \hat \psi_1 \d \xi &= 2 \\
\int_{-1}^1 \hat \psi_1 \hat \psi_2 \d \xi &= 0 \\
\int_{-1}^1 \hat \psi_2 \hat \psi_2 \d \xi &= \frac{2}{3}
\end{align*}
$$

So our resulting equations are

$$
\begin{align*}
\uja(0) &= \frac{1}{2} \int_{-1}^1 u_0(x(\xi)) \d \xi \\
\ujb(0) &= \frac{3}{2} \int_{-1}^1 u_0(x(\xi)) \d \xi
\end{align*}
$$

We can use quadrature to integrate $u_0(x(\xi))$:

$$
\int_{-1}^1 f(\xi) \d \xi \approx f\parens{-\frac{1}{\sqrt 3}} + f\parens{\frac{1}{\sqrt 3}}
$$

## Solving a PDE

### Step 1

Some expansion coefficients depend on time:

$$
\vja \parens{ \dbyd{}{t} \uja(t)  \int_{K_j} \psi_1 \psi_1 \d x + \dbyd{}{t} \ujb(t) \underbrace{\int_{K_j} \psi_1 \psi_2 \d x}_{=0} } \\
+ \vja \parens{ \dbyd{}{t} \uja(t)  \underbrace{\int_{K_j} \psi_2 \psi_1 \d x}_{=0} + \dbyd{}{t} \ujb(t) \int_{K_j} \psi_2 \psi_2 \d x } \\
- \vja \parens{ \int_{K_j} f(u_h^j(x, t)) \underbrace{\partial \psi_1}_{=0} \d x } - \vjb \parens{ \int_{K_j} f(u_h^j(x, t)) \partial \psi_2 \d x } \\
+ \vjb \parens{\hat f_j \psi_1(x_j)} + + \vjb \parens{\hat f_j \psi_1(x_j)}
$$

### Step 3+4

Map to reference element and note

$$
\begin{array}{cc}
\psi_1(x_j) = \hat \psi_1(1) = 1 & \psi_2(x_j) = \hat \psi_2(1) = 1 \\
\psi_1(x_{j-1}) = \hat \psi_1(-1) = 1 & \psi_2(x_{j-1}) = \hat \psi_2(-1) = -1 \\
\int_{-1}^1 \hat \psi_1 \hat \psi_1 \d \xi = 2 & \int_{-1}^1 \hat \psi_2 \hat \psi_2 \d \xi = \frac{2}{3}
\end{array}
$$

applying this to our equations for the coefficients

$$
\begin{align*}
0 &= \dbyd{}{t} \hat u_1^j(t) \int_{K_j} \psi_1 \psi_1 \d x - \hat f_j \psi_1(x_j) - \hat f_{j-1} 
\psi_1(x_{j-1}) \\
\dbyd{}{t} \hat u_1^j(t) &= \frac{1}{h} \parens{ \hat f_{j-1} - \hat f_j } \\
0 &= \dbyd{}{t} \hat u_2^j(t) \int_{K_j} \psi_2 \psi_2 \d x - \hat f_j [...] - \hat f_{j-1} [...] \\
\dbyd{}{t} \hat u_2^j(t) &= \frac{3}{h} \parens{ \int_{-1}^1 f\parens{u_{?} (x(\xi), t) + 1} \d \xi - \parens{ \hat f_j - \hat f_{j-1} }}
\end{align*}
$$

### Time stepping

Since our DG method is second-order accurate in space, we want a second order accurate time stepping method, e.g. 2nd order Runge-Kutta:

$$
\begin{align*}
\xi_1 &= \hat u^{n-1} + \Delta t L\parens{\hat u^{n-1}} \\
\xi_2 &= \frac{1}{2}\hat u^{n-1} + \frac{1}{2} \xi_1 + \frac{1}{2}\Delta t L\parens{\xi_1} \\
\hat u^n &= \xi_2
\end{align*}
$$

This is an explicit time stepping method so it is not unconditionally stable, so we need an upper bound on our time step to guarantee stability. The CFL condition is

$$
\abs{\frac{\Delta t}{h} \lambda(u_h^j)} \leq c \text{ for all } j
$$

For FV, we typically use $c \leq 1$. For DG with $k=1$, we need smaller time steps, so we typically use $c \leq 1/3$.

## Convergence

By Godonov's theorem, DG is not monotone (only first order schemes can be monotone). Can we still guarantee convergence to the entropy solution?

### Total variation

For a function $u$, the total variation is

$$
TV(u(\cdot, t)) = \sup_{h \in \R \setminus \curlies{0}} \frac{1}{h} \int_\R \abs{u(\xi + h, t) - u(\xi, t)} \d \xi
$$

The theorem by Godlewski and Raviart states that the entropy solution is total-variation diminishing, i.e.

$$
TV(u(\cdot, t)) \leq TV(u_0(\cdot)) \text{ for } t > 0
$$

So we want our numerical method to mimic this property at the discrete level

### Discrete total variation

The expansion coefficients $\hat u_1^j$ are the local means of each element $K_j$. The **total variation in the means** is:

$$
TV((\hat u_1)^n) = \sum_{j=1}^{N-1} \abs{(\hat u_1^{j-1})^n - (\hat u_1^j)^n}
$$

A method is **total variation diminishing in the means** (TVDM) if

$$
TV((\hat u_1)^n) \leq TV((\hat u_1)^{n-1})
$$

Since the DG method is not monotone, we may have spurious (non physical) oscillations in our solution which increase the total variation. So a method where the total variation does not increase will not have spurious oscillations.

Our DG method is not automatically TVDM, so we need to modify the solution (i.e. post processing) using **slope limiters**.

The DG solution on each element is

$$
u_h \bigg \vert_{K_j}(x) = \hat u_1^j + \hat u_2^j \psi_2(x)
$$

We can make our solution TVDM by limiting the slope $\hat u_2^j$:

$$
u_h \bigg \vert_{K_j}(x) = \hat u_1^j + m\parens{\hat u_2^j, \hat u_1^{j+1} - \hat u_1^j, \hat u_1^j - \hat u_1^{j-1}} \psi_2(x)
$$

When we use Runge Kutta time integration, we apply the slope limiter at each stage:

$$
\begin{align*}
\xi_1 &= \hat u^{n-1} + \Delta t L\parens{\hat u^{n-1}} \\
\tilde \xi_1 &= \text{slope limiter}(\xi_1) \\
\xi_2 &= \frac{1}{2}\hat u^{n-1} + \frac{1}{2} \xi_1 + \frac{1}{2}\Delta t L\parens{\xi_1} \\
\tilde \xi_2 &= \text{slope limiter}(\xi_2) \\
\hat u^n &= \xi_2
\end{align*}
$$

#### Minmod slope limiter

$$
m(a_1, a_2, a_3) = \begin{cases}
s \min(\abs{a_1}, \abs{a_2}, \abs{a_3} & \text{ if } s = \sign(a_1) = \sign(a_2) = \sign(a_3) \\
0 & \text{otherwise}
\end{cases}
$$

<img src="/Users/rikin/Library/Application Support/typora-user-images/image-20240402122825766.png" alt="image-20240402122825766" style="zoom: 33%;" />

### RKDG with minmod is TVDM

- no one has been able to show that RKDG converges to the entropy solution
- only scalar hyperbolic conservation laws have been proven to converge to the entropy solution with certain implicit integrators

### Why use a solver that doesn't provably give us the entropy solution?

Higher order (DG() methods are generally not proven to converge to the entropy solution, however they are much less numerically diffusive.

# 05

$$
\newcommand{\x}{\mathbf x}
\newcommand{\y}{\mathbf y}
\newcommand{\f}{\mathbf f}
\newcommand{\j}{\mathbf j}
\newcommand{\n}{\mathbf n}
\newcommand{\v}{\mathbf v}
\newcommand{\U}{\mathbf U}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\norm}[1]{\big\lVert #1 \big\rVert}
\newcommand{\parens}[1]{\left( #1 \right)}
\newcommand{\brackets}[1]{\left[ #1 \right]}
\newcommand{\angles}[1]{\left\langle #1 \right\rangle}
\newcommand{\curlies}[1]{\left\lbrace #1 \right\rbrace}
\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\d}{\, \text{d}}
\newcommand{\dbyd}[2]{\frac{\d #1}{\d #2}}
\newcommand{\partials}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\BigO}{\mathcal O}
\newcommand{\disclapl}[1][]{\partial_{#1} \overline \partial_{#1}}
$$

*Proof.*

Assume $E_k$ is stable and $\abs{\tilde E(\xi_0)} > 1$ for $\xi_0 \in \R$.

$E_k$ is stable means

$$
\norm{U^n}_{\infty, h} = \norm{E_k^n u}_{\infty, h} \leq \norm{u}_{\infty, h}
$$

Let $u_j = \exp(ij\xi_0) \epsilon$, then $\norm{u}_{\infty, h} = \epsilon$

$$
U_j^1 = \sum_p a_p \exp(i(j-p\xi_0))\epsilon = \underbrace{\sum_p a_p \exp(-ip\xi_0)}_{\tilde E(\xi)} \underbrace{\exp(ij\xi_0)\epsilon}_{u_j}
$$

Repeated applications:

$$
U_j^n = \brackets{\tilde E(\xi_0)}^n u_j
$$

so that

$$
\norm{U_j^n}_{\infty, h} = \abs{\tilde E(\xi_0)}^n \epsilon \to \infty \text{ as } n \to \infty
$$

Since $\norm{u}_{\infty, h} = \epsilon$ this contradicts stability

Necessary (for stability is max-norm):

$\abs{\tilde E(\xi)} \leq 1$ for all $\xi \in \R$

$$
\begin{align*}
\abs{1 - 4\lambda \sin^2\parens{\frac{1}{2} \xi}} \leq 1
\end{align*}
$$


In the $\ell^2$-norm, $\abs{\tilde E(\xi)} \leq 1$ for all $\xi \in \R$ (Von Neumann's condition) is a necessary and sufficient condition for stability

Let $V = \curlies{ V_j}_\infty^\infty$ be a mesh function in the space variable.

The $\ell^2$-norm for mesh functions is defined as

$$
\norm{V}_{2, h} = \sqrt{h\sum_{j=-\infty}^\infty V_j^2}
$$

The set $\ell_{2, h}$ is defined as

$$
\ell_{2, h} = \curlies{  V : \norm{V}_{2, h} < \infty}
$$

The discrete fourier transform for a mesh function is

$$
\hat V(\xi) = h\sum_{j=-\infty}^\infty V_j \exp(-ij\xi)
$$

The inverse fourier transform is

$$
V_j = \frac{1}{2\pi h} \int_{-\pi}^\pi \hat V(\xi) \exp(ij\xi) \d\xi
$$

Theorem 9.3

$\abs{\tilde E(\xi)} \leq 1$ if and only if for some $c$,

$$
\norm{E_k^n V}_{2, h} \leq c\norm{v}_{2, h}
$$

*Proof.*

We have

$$
(E_k V)_j = \sum_p a_p V_{j-p}
$$

Take the fourier transform:

$$
\begin{align*}
\hat{E_k V}(\xi)
&= h\sum_{j=-\infty}^\infty \sum_p a_p V_{j-p} \exp(-ij\xi) \\
&= \underbrace{\sum_p a_p \exp(-ip\xi)}_{\tilde E(\zeta)} \underbrace{h\sum_{j=-\infty}^\infty V_{j-p} \exp(-i(j-p)\xi)}_{\hat V(\xi)} \\
\text{and so, }\ \hat{E_k^n V}(\xi) &= \brackets{\tilde E(\xi)}^n V(\xi)
\end{align*}
$$

Using Parseval's relation,

$$
\norm{E_k^n V}^2_{2, h} = \frac{1}{2\pi h} \int_{-\pi}^\pi \abs{\hat{E_k^n V}(\xi)}^2 \d\xi = \frac{1}{2\pi h} \int_{-\pi}^\pi \abs{\tilde E(\xi)^n \hat V(\xi)}^2 \d\xi
$$

and

$$
\norm{v}^2_{2, h } = \frac{1}{2 \pi h} \int_{-\pi}^\pi \abs{\hat V(\xi)}^2 \d\xi
$$

$$
\begin{align*}
\norm{E_k V}_{2, h} &\leq \norm{v}_{2, h} \\
&\Leftrightarrow \\
\int_{-\pi}^\pi \abs{\tilde E(\xi)}^2 \abs{\hat V(\xi)}^2 \d\xi &\leq c^2 \int_{-\pi}^\pi \abs{\hat V(\xi)}^2 \d \xi \\
&\Leftrightarrow \\
\abs{\tilde E(\xi)}^n &\leq c \text{ for } n \geq 1,  \xi \in \R \\
&\Leftrightarrow \\
\abs{\tilde E(\xi)} &\leq 1 \text{ for } \xi \in \R
\end{align*}
$$

9.2 The mixed initial-boundary value problem

Model problem

$$
\begin{cases}
\partials{u}{t} = \partials{^2 u}{x^2} & \Omega = (0, 1), t > 0 \\
u(0, t) = u(1, t) = 0 & \text{(boundary conditions)} \\
u(x, 0) = u(x) & \text{(initial conditions)}
\end{cases}
$$

With a finited difference and forward euler discretization scheme, this turns into

$$
\begin{cases}
\partial_t U_j^n = \disclapl[x] U_j^n & j = 1, 2, ..., M-1, n > 0 \\
U_0^n = U_m^n = 0 & \text{(boundary conditions)} \\
U_j^0 = V_j = u(x_j) & \text{(initial conditions)}
\end{cases}
$$

To deal with boundary conditions we define $\ell_n^0$, the space of $M+1$-vectors $\curlies{ U_j}_{j\in(0, ..., M)}$ with $V_0 = V_m = 0$ for $\mathbf V \in \ell_n^0$.

For $U^n \in \ell_n^0$ and $j = 1, ..., M-1$,

$$
U_j^{n+1} = (E_k U^n)_j = \lambda (U_{j-1}^n + U_{j+1}^n) + (1 - 2\lambda) U_j^n = (E_k^n V)_j
$$

On the bounded domain:

$$
\norm{U}_{\infty, h} = \max_{0 \leq j \leq M} \abs{U_j}
$$

As in the case of the pure initial value problem, we have

1. For $\lambda \leq \frac{1}{2}$

	$$
	\norm{E_k^n V}_{\infty, h} \leq \norm{V}_{\infty, h}
	$$

2. FD + Euler is unstable for $\lambda > \frac{1}{2}$
3. Constant
4. $\norm{U^n - u^n}_{\infty, h} \leq ch^2 k^n$

But note that $\lambda \leq \frac{1}{2}$ is a very severe restriction! $\lambda = k/h^2$, so for high resolution meshes we need very small time steps

Ideally, we want $k \sim h$

We should use backward Euler time integration instead of forward Euler:

Turning our PDE into an ODE in time,

$$
\begin{cases}
\dbyd{U_j(t)}{t} = \disclapl[x] U_j(t) & j = 1, ..., M-1, t > 0 \\
U_0(t) = U_M(t) = 0 & \text{(boundary conditions)} \\
U_j(0) = u(x_j) & \text{(initial conditions)}
\end{cases}
$$

Useful ways of denoting FD+BE for this problem:

1. $\displaystyle U_j^{n+1} = U_j^n + \frac{k}{h^2} (U_{j+1}^{n+1} - 2U_j^{n+1} + U_{j-1}^{n+1})$
2. $\displaystyle \frac{U_j^{n+1} - U_j^n}{k} = \frac{U_{j+1}^{n+1} - 2U_j^{n+1} + U_{j-1}^{n+1}}{h^2}$
3. recall $\displaystyle \overline \partial_t U_j^{n+1} = \frac{U_j^{n+1} - U_j^n}{k}$, then $\overline \partial_t U_j^{n+1} = \disclapl[x] U_j^{n+1}$

with boundary conditions $U_0^{n+1} = U_M^{n+1} = 0$ and $U_j^0 = V_j$

Setting $\lambda = k/h^2$, we have

$$
\begin{cases}
(1 + 2\lambda) U_j^{n+1} - \lambda(U_{j-1}^{n+1} + U_{j+1}^{n+1}) = U_j^n & j = 1, ..., M-1 \\
U_0^{n+1} = U_m^{n+1} = 0
\end{cases}
$$

Let $\U^n = (U_1^n, ..., U_{M-1}^n)$. Then we can write our scheme as a linear system:

$$
\underbrace{
\begin{bmatrix}
(1 + 2\lambda) & -\lambda &  \\ -\lambda & (1 + 2\lambda) & -\lambda \\ & \ddots & \ddots & \ddots \\ & & -\lambda & (1 + 2\lambda) & -\lambda \\ & & & -\lambda & (1 + 2\lambda) &
\end{bmatrix}
}_B
\underbrace{
\begin{bmatrix}
U_1^{n+1} \\ \vdots \\ U_{M-1}^{n+1}
\end{bmatrix}
}_{\U^{n+1}}
&=
\underbrace{
\begin{bmatrix}
U_1^n \\ \vdots \\ U_{M-1}^n
\end{bmatrix}
}_{\U^n}
$$

Since $\lambda > 0$, $B$ is diagonally dominant, so $B$ is non-singular, so a unique solution to the linear system exists!

Define

$$
(B_{kh} V)_j = (1 + 2\lambda) V_j - \lambda(V_{j-1} + V_{j+1}) = V_j - k\disclapl[x] V_j
$$

Then ...

Define $E_k$ as $\inv B_{kh}$, i.e. $U^{n+1} = \inv B_{kh} U^n = E_k U^n$

This helps us see that the scheme is stable for all $k > 0$:

Let $s$ be such that

$$
\norm{U^{n+1}}_{\infty, h} = \abs{U_{s}^{n+1}}
$$

The since we know that $(1 + 2\lambda) U_j^{n+1} - \lambda (U_{j-1}^{n+1} + U_{j+1}^{n+1}) = U_j^n$, we can rearrange to find

$$
\begin{align*}
U_j^{n+1} &= \frac{1}{1 + 2\lambda} \brackets{\lambda (U_{j-1}^{n+1} + U_{j+1}^{n+1}) + U_j^n} \\
\norm{U^{n+1}}_{\infty, h} = \abs{U_s^{n+1}} &= \frac{1}{1 + 2\lambda} \abs{\lambda (U_{s-1}^{n+1} + U_{s+1}^{n+1}) + U_s^n} \\
&\leq \frac{1}{1 + 2\lambda} (\lambda (\abs{(U_{s-1}^{n+1}} + \abs{U_{s+1}^{n+1}}) + \abs{U_s^n}) \tag{triangle ineq} \\
&\leq \frac{1}{1 + 2\lambda} (2\norm{U^{n+1}}_{\infty, h} + \norm{U^n}_{\infty, h})
\end{align*}
$$
